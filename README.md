# sql-rag
Hybrid SQL + Agentic RAG System

A cost-efficient, metadata-aware Hybrid Retrieval System that combines structured SQL querying with semantic vector search using FAISS â€” powered by an agent-based routing architecture.

This project demonstrates how to move beyond naive RAG pipelines and build production-style retrieval systems that are efficient, grounded, and hallucination-resistant.

ğŸ” Problem Statement

Traditional RAG systems:

Perform vector search over the entire dataset

Increase latency and token usage

Struggle with structured queries (COUNT, FILTER, GROUP BY)

Risk hallucinated aggregations

Pure SQL systems:

Cannot understand unstructured text

Cannot answer semantic questions like
â€œWhat risks were identified?â€

â“ So how do we combine both efficiently?
ğŸ§  Solution: Hybrid SQL + Agentic RAG Architecture

This system intelligently routes user queries into two optimized paths:

1ï¸âƒ£ Structured Query Path (SQL Execution)

For aggregation, counting, and filtering queries:

LLM generates SQL query

SQL is sanitized

Query executes directly on SQLite

Real database result is returned

âœ… No hallucinated numbers
âœ… No fabricated data
âœ… Fully grounded answers

2ï¸âƒ£ Semantic Query Path (Optimized RAG)

For document understanding queries:

Extract structured filters (e.g., department, year)

Retrieve matching document IDs using SQL

Perform FAISS similarity search

Restrict retrieved documents using metadata (doc_id)

Generate answer strictly from retrieved context

âš¡ Key Optimization: Metadata-Aware Vector Retrieval

Instead of running FAISS across the entire dataset:

We store doc_id as metadata in FAISS

Use SQL to narrow down relevant IDs first

Filter vector results using those IDs

docs = vectorstore.similarity_search(question, k=20)

docs = [
    doc for doc in docs
    if doc.metadata["doc_id"] in filtered_ids
]
ğŸ”¥ Benefits

Reduced search space

Lower latency

Reduced token usage

Improved relevance

Hallucination mitigation

This mirrors production-grade retrieval strategies used in scalable AI systems.

ğŸ— Architecture Overview

User Query
â†“
Router Agent (Gemini 2.5 Flash)
â†“
ğŸ”€ Decision Layer

Structured Query

â†’ SQL Generation
â†’ SQLite Execution
â†’ Direct Answer

Semantic Query

â†’ SQL Metadata Filtering
â†’ Retrieve Document IDs
â†’ FAISS Vector Search (Restricted)
â†’ Context-Based LLM Answer

ğŸ›  Tech Stack

LangGraph â€“ Agent workflow orchestration

Gemini 2.5 Flash â€“ Routing + Generation

HuggingFace Embeddings (MiniLM) â€“ Text embeddings

FAISS â€“ Vector similarity search

SQLite â€“ Structured storage

Streamlit â€“ UI interface

ğŸ“‚ Database Schema

Example table:

documents(
    id INTEGER PRIMARY KEY,
    department TEXT,
    year INTEGER,
    title TEXT,
    category TEXT,
    author TEXT,
    created_date TEXT,
    content TEXT
)

Supports both structured metadata queries and semantic retrieval.

ğŸš€ Installation & Setup
1ï¸âƒ£ Clone the repository
git clone <your-repo-url>
cd <project-folder>
2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

(Or manually install: streamlit, langgraph, faiss-cpu, sentence-transformers, etc.)

4ï¸âƒ£ Add Gemini API Key

Create a .env file:

GOOGLE_API_KEY=your_api_key_here
5ï¸âƒ£ Run the application
streamlit run app.py
ğŸ§ª Example Queries
Structured

How many documents were created in 2023?

Who authored the Legal document?

Count HR reports.

Semantic

What workplace risks were identified?

What compliance gaps were mentioned?

Summarize the HR report.

Hybrid

What risks were identified in HR documents from 2023?

ğŸ¯ Key Highlights

âœ” Agent-based routing
âœ” SQL grounding to prevent hallucination
âœ” Metadata-aware vector search
âœ” Cost-efficient retrieval strategy
âœ” Production-style hybrid architecture

ğŸ§  What This Demonstrates

This project shows:

Understanding of RAG limitations

Cost optimization in retrieval systems

Hybrid structured + semantic search

Hallucination mitigation techniques

Production-oriented system design

ğŸ“Œ Future Improvements

Persistent FAISS indexing

Multi-table support

Query validation & SQL injection protection

Deployment to cloud

Scalable ingestion pipeline

ğŸ¤ Connect

If you're building scalable AI retrieval systems or working on intelligent database interfaces, feel free to connect ğŸš€
